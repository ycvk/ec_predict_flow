---
sidebar_position: 4
---

# 模型解释

模型解释模块使用SHAP（SHapley Additive exPlanations）生成特征解释图，帮助理解模型决策过程。

## 功能说明

- 使用SHAP分析特征重要性
- 生成特征贡献可视化图表
- 识别关键预测特征

## 使用步骤

1. 确保已完成模型训练
2. 进入"模型解释"模块
3. 选择要分析的模型
4. 点击"生成解释"按钮
5. 已生成的SHAP解释列表会显示解释图的目录，点击查看可以查看列表和网格视图的解释图


## SHAP图表类型

- **Summary Plot**: 特征重要性总览
- **Summary Dot**: 特征贡献瀑布图
- **Dependence Plot**: 单个特征的影响分析


## 应用场景

- 理解模型预测逻辑
- 发现关键特征
- 反映关键特征的可解释阈值



## 输出文件

SHAP图表保存在backend文件夹的 `data/plots/` 目录下的文件夹中。
